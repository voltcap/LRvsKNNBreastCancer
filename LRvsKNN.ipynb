{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data = load_breast_cancer()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "print(\"First 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"Feature names:\")\n",
        "for i, feature in enumerate(data.feature_names):\n",
        "    print(f\"{i+1:2d}. {feature}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Target variables:\")\n",
        "print(f\"Target names: {data.target_names}\")\n",
        "print(f\"Target values: {pd.Series(data.target).value_counts().to_dict()}\")\n"
      ],
      "metadata": {
        "id": "bLyRmzXncczm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "feaTrain, feaTest, tarTrain, tarTest = train_test_split(data.data, data.target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5on2-XL3X_OM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logRegModel = LogisticRegression(max_iter=5000, random_state=42)\n",
        "logRegModel.fit(feaTrain, tarTrain)\n",
        "\n",
        "tarPred = logRegModel.predict(feaTest)\n",
        "print(tarPred)\n",
        "print(f\"Class 0 (Malignant): {(tarPred == 0).mean() * 100:.2f}%\")\n",
        "print(f\"Class 1 (Benign): {(tarPred == 1).mean() * 100:.2f}%\")\n",
        "print(tarPred.mean())\n"
      ],
      "metadata": {
        "id": "XIyJsZVnf72B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confMatrix = confusion_matrix(tarTest, tarPred)\n",
        "print(\"Confusion matrix:\")\n",
        "print(confMatrix)\n",
        "\n",
        "tarPredProb = logRegModel.predict_proba(feaTest)[:, 1]\n",
        "fpr, tpr, thresholds = roc_curve(tarTest, tarPredProb)\n",
        "aucScore = auc(fpr, tpr)\n",
        "\n",
        "print(f\"\\n AUC score: {aucScore:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blueviolet', lw=2, label=f'chad AUC:{aucScore:.4f}')\n",
        "plt.plot([0, 1], [0, 1], color='deepskyblue', lw=2, linestyle='--', label='basic loser classifier')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False pos')\n",
        "plt.ylabel('True pos')\n",
        "plt.title('Logistic regression ROC curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XicOX_x1bnrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "feaTrainScaled = scaler.fit_transform(feaTrain)\n",
        "feaTestScaled = scaler.transform(feaTest)"
      ],
      "metadata": {
        "id": "Yj6jMzJvdDuI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "paramGrid = {\n",
        "    'n_neighbors': range(1, 22), 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "gridSearch = GridSearchCV(knn, paramGrid, cv=5, scoring='accuracy')\n",
        "gridSearch.fit(feaTrainScaled, tarTrain)\n",
        "\n",
        "bestParams = gridSearch.best_params_\n",
        "bestScore = gridSearch.best_score_\n",
        "\n",
        "print(\"Best parameters:\")\n",
        "print(bestParams)\n",
        "print(f\"Best cross validation accuracy: {bestScore:.4f}\")"
      ],
      "metadata": {
        "id": "Ck_-nzJKfazM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knnBest = KNeighborsClassifier(n_neighbors=8, weights='uniform', metric='euclidean')\n",
        "knnBest.fit(feaTrainScaled, tarTrain)\n",
        "\n",
        "knnPred = knnBest.predict(feaTestScaled)\n",
        "knnPredProb = knnBest.predict_proba(feaTestScaled)[:, 1]\n",
        "\n",
        "knnConfMatrix = confusion_matrix(tarTest, knnPred)\n",
        "print(\"confusion matrix:\")\n",
        "print(knnConfMatrix)\n",
        "\n",
        "knnFpr, knnTpr, knnThresholds = roc_curve(tarTest, knnPredProb)\n",
        "knnAucScore = auc(knnFpr, knnTpr)\n",
        "\n",
        "print(f\"\\nAUC score: {knnAucScore:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(knnFpr, knnTpr, color='olivedrab', lw=2, label=f'KNN AUC: {knnAucScore:.4f}')\n",
        "plt.plot([0, 1], [0, 1], color='lawngreen', lw=2, linestyle='-', label='Massive L')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False pos')\n",
        "plt.ylabel('True pos')\n",
        "plt.title('KNN ROC curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7cEbMEILhg4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"comparison\")\n",
        "print(f\"LR AUC: {aucScore:.4f}\")\n",
        "print(f\"KNN AUC: {knnAucScore:.4f}\")\n",
        "\n",
        "print(\"\\nConfmatrix\")\n",
        "print(\"LR:\")\n",
        "print(confMatrix)\n",
        "print(\"\\nKNN:\")\n",
        "print(knnConfMatrix)\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "lr_precision = precision_score(tarTest, tarPred)\n",
        "lr_recall = recall_score(tarTest, tarPred)\n",
        "lr_f1 = f1_score(tarTest, tarPred)\n",
        "knn_precision = precision_score(tarTest, knnPred)\n",
        "knn_recall = recall_score(tarTest, knnPred)\n",
        "knn_f1 = f1_score(tarTest, knnPred)\n",
        "\n",
        "print(f\"{'Metric':<15} {'LR':<20} {'KNN':<10}\")\n",
        "print(f\"{'Precision':<15} {lr_precision:<20.4f} {knn_precision:<10.4f}\")\n",
        "print(f\"{'Recall':<15} {lr_recall:<20.4f} {knn_recall:<10.4f}\")\n",
        "print(f\"{'F1-Score':<15} {lr_f1:<20.4f} {knn_f1:<10.4f}\")"
      ],
      "metadata": {
        "id": "-6cgZWuNWVDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the graphs, AUC score and the metrics i printed above, logistic regression outperforms Knn in AUC, recall and f1 score but knn has more true positives, 41 and less false positives. Both have strengths but overall, LR is the winner, due to AUC, F1, Recall and 1 false negative, compared to 3 missed cancer cases from knn"
      ],
      "metadata": {
        "id": "wQ7q6_-JYSef"
      }
    }
  ]
}